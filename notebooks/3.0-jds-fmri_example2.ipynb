{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fMRI example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "from os.path import join\n",
    "import glob\n",
    "import pandas as pd\n",
    "import tensorflow as tf \n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def center_normalize(x):\n",
    "    x_mean_rows = np.mean(x,1).reshape(x.shape[0],1)\n",
    "    x_std_rows = np.std(x,1).reshape(x.shape[0],1)\n",
    "    return (x - x_mean_rows) / x_std_rows\n",
    "\n",
    "def onehot(y):\n",
    "    ynp=np.array(y)\n",
    "    y_onehot=[0]*len(ynp)\n",
    "    for i,j in enumerate(ynp):\n",
    "        y_onehot[i]=[0]*ynp.max()\n",
    "        y_onehot[i][j-1]=1\n",
    "        \n",
    "    return y_onehot\n",
    "def recode20(y):\n",
    "    y_r = np.empty(y.shape)\n",
    "    y_r[y == 1] = 0\n",
    "    y_r[y == 2] = 1\n",
    "    y_r[y == 3] = 2\n",
    "    return y_r\n",
    "\n",
    "from scipy import stats    \n",
    "def get_results():\n",
    "    print('Logistic regression')\n",
    "    print('mean accuracy: ' + str(np.mean(scores_reg)))\n",
    "    print('Logistic regression (1samp ttest):')\n",
    "    print(stats.ttest_1samp(np.mean(scores_reg,1),.33))\n",
    "    print\n",
    "    print('SVM')\n",
    "    print('mean accuracy: ' + str(np.mean(scores_svm)))\n",
    "    print('1samp ttest:')     \n",
    "    print(stats.ttest_1samp(np.mean(scores_svm,1),.33))\n",
    "    print\n",
    "    print('Neural network')\n",
    "    print('mean accuracy: ' + str(np.mean(scores_nn)))\n",
    "    print('1samp ttest:')\n",
    "    print(stats.ttest_1samp(np.mean(scores_nn,1),.33))\n",
    "    \n",
    "def model_svm(x_train,y_train,x_test,y_test):\n",
    "    C = 1  # SVM regularization parameter\n",
    "    svc = svm.LinearSVC(C=C).fit(x_train, y_train)\n",
    "    y_pred = svc.predict(x_test)\n",
    "    return accuracy_score(y_test, y_pred)\n",
    "\n",
    "def model_tf_regression(x_train,y_train,x_test,y_test):\n",
    "    tf.reset_default_graph()\n",
    "    sess = tf.InteractiveSession()\n",
    "\n",
    "    x = tf.placeholder(tf.float32, shape=[None, x_train.shape[1]])\n",
    "    y_ = tf.placeholder(tf.float32, shape=[None, 3])\n",
    "\n",
    "\n",
    "    W = tf.Variable(tf.zeros([x_train.shape[1],3]))\n",
    "    b = tf.Variable(tf.zeros([3]))\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    y = tf.matmul(x,W) + b\n",
    "\n",
    "    cross_entropy = tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))\n",
    "    \n",
    "    ##train\n",
    "    train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "    for i in range(1000):\n",
    "        train_step.run(feed_dict={x: x_train.tolist(), y_: onehot(y_train)})\n",
    "    \n",
    "    #tf.argmax gives an index of the highest entry in a tensor along some axis\n",
    "    correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "\n",
    "    #we can take this list of booleans and calculate the fraction correct\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    return accuracy.eval(feed_dict={x: x_test.tolist(), y_: onehot(y_test)})\n",
    "    sess.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def model_tf_nn(x_train,y_train,x_test,y_test):\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    n_inputs = x_train.shape[1]\n",
    "    n_hidden1 = 10\n",
    "    n_outputs = 3\n",
    "    learning_rate = 0.01\n",
    "\n",
    "\n",
    "    def neuron_layer(X, n_neurons, name, activation=None):\n",
    "        with tf.name_scope(name):\n",
    "            n_inputs = int(X.get_shape()[1])\n",
    "            stddev = 1 / np.sqrt(n_inputs)\n",
    "            init = tf.truncated_normal((n_inputs, n_neurons), stddev=stddev)\n",
    "            W = tf.Variable(init, name=\"weights\")\n",
    "            b = tf.Variable(tf.zeros([n_neurons]), name=\"biases\")\n",
    "            Z = tf.matmul(X, W) + b\n",
    "            if activation==\"relu\":\n",
    "                return tf.nn.relu(Z)\n",
    "            else:\n",
    "                return Z\n",
    "    X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "    y = tf.placeholder(tf.int64, shape=(None), name=\"y\")\n",
    "\n",
    "    with tf.name_scope(\"dnn\"):\n",
    "        hidden1 = neuron_layer(X, n_hidden1, \"hidden1\", activation=\"relu\")\n",
    "        logits = neuron_layer(hidden1, n_outputs, \"output\")\n",
    "        \n",
    "    with tf.name_scope(\"loss\"):\n",
    "        xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "        loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "    with tf.name_scope(\"train\"):\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "        training_op = optimizer.minimize(loss)\n",
    "\n",
    "    with tf.name_scope(\"eval\"):\n",
    "        correct = tf.nn.in_top_k(logits, y, 1)\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "        prediction=tf.argmax(logits,1)\n",
    "            \n",
    "    init = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    n_epochs = 20\n",
    "    acc_test_high = 0.0\n",
    "\n",
    "    sess = tf.InteractiveSession()\n",
    "\n",
    "    sess.run(init)\n",
    "    predictions = np.empty(x_test.shape[0])\n",
    "    for epoch in range(n_epochs):\n",
    "        for i in range(x_train.shape[0]):\n",
    "            x_data = x_train[i,:].reshape([1,x_train.shape[1]])\n",
    "            y_data = np.array([y_train[i]])\n",
    "            sess.run(training_op, feed_dict={X: x_data, y: y_data })\n",
    "        \n",
    "        acc_train = accuracy.eval(feed_dict={X: x_train, y: y_train})\n",
    "        acc_test = accuracy.eval(feed_dict={X: x_test, y: y_test})\n",
    "        if acc_test > acc_test_high:\n",
    "            acc_test_high = acc_test\n",
    "            predictions = prediction.eval(feed_dict={X: x_test})\n",
    "#         print(epoch, \"Train accuracy:\", acc_train, \"Test accuracy:\", acc_test)\n",
    "\n",
    "    # save_path = saver.save(sess, \"./one_layer.ckpt\")\n",
    "    return acc_test_high,predictions\n",
    "    sess.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data dir test \n",
    "data_dir = '../data/greco_mri'\n",
    "behav_dir = '../data/greco_behav'\n",
    "\n",
    "#rois\n",
    "rois = ['left_CA1','right_CA1','left_DG','right_DG'];\n",
    "\n",
    "#subjec list\n",
    "subjects = ['S1_A','S2_B','S3_A','S4_A','S5_A','S6_A','S7_A','S8_B',\n",
    "            'S9_A','S10_B','S11_B','S12_B','S13_B','S14_B','S15_B',\n",
    "            'S16_A','S21_B','S22_B','S24_A'];\n",
    "# subjects = ['S1_A','S3_A','S4_A','S5_A','S6_A','S7_A',\n",
    "#             'S9_A','S10_B','S11_B','S12_B','S14_B','S15_B',\n",
    "#             'S16_A','S21_B','S22_B','S24_A'];\n",
    "subjects = np.array(subjects);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Three models with cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.float32' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-64f13839394a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m#         scores_svm[i,run] =  model_svm(x_train,y_train,x_test,y_test)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m#         scores_reg[i,run] = model_tf_regression(x_train,y_train,x_test,y_test)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mscores_nn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mall_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_tf_nn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train_r\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test_r\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mall_y_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.float32' object is not iterable"
     ]
    }
   ],
   "source": [
    "scores_svm = np.empty((subjects.shape[0],4))\n",
    "scores_reg = np.empty((subjects.shape[0],4))\n",
    "scores_nn = np.empty((subjects.shape[0],4))\n",
    "all_pred = np.empty()\n",
    "all_y_test= np.empty()\n",
    "for i,subj in enumerate(subjects):\n",
    "    for run in [0,1,2,3]:\n",
    "       \n",
    "        behav = pd.read_table(join(behav_dir,subj,subj + '.txt'))\n",
    "\n",
    "        fname = join(data_dir,subj + '_right_DG.csv')\n",
    "        betas= pd.read_csv(fname,header=None)\n",
    "\n",
    "        test_ind   = behav['run_num'] == run\n",
    "        train_ind  = behav['run_num'] != run\n",
    "        y_test     = behav['currCity'][test_ind].as_matrix()        \n",
    "        y_test_r   = recode20(y_test)\n",
    "\n",
    "        y_train    = behav['currCity'][train_ind].as_matrix()\n",
    "        y_train_r  = recode20(y_train)\n",
    "\n",
    "        x_test = center_normalize(betas[test_ind].as_matrix())\n",
    "        x_train = center_normalize(betas[train_ind].as_matrix())\n",
    "#         scores_svm[i,run] =  model_svm(x_train,y_train,x_test,y_test)\n",
    "#         scores_reg[i,run] = model_tf_regression(x_train,y_train,x_test,y_test)\n",
    "        scores_nn[i,run],all_pred[i,run] = model_tf_nn(x_train,y_train_r,x_test,y_test_r)\n",
    "        all_y_test[i,run] = x_test\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression\n",
      "mean accuracy: 0.324736842788\n",
      "Logistic regression (1samp ttest):\n",
      "Ttest_1sampResult(statistic=-0.30706705741261137, pvalue=0.76231644869561455)\n",
      "\n",
      "SVM\n",
      "mean accuracy: 0.324736842105\n",
      "1samp ttest:\n",
      "Ttest_1sampResult(statistic=-0.35242936701678962, pvalue=0.72860912450487225)\n",
      "\n",
      "Neural network\n",
      "mean accuracy: 0.401578946137\n",
      "1samp ttest:\n",
      "Ttest_1sampResult(statistic=5.9286295787179872, pvalue=1.3048049133180781e-05)\n"
     ]
    }
   ],
   "source": [
    "get_results()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
